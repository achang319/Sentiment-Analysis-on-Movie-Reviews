{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, string, re, spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_files = glob.glob(\"aclImdb/train/pos/*.txt\")\n",
    "train_neg_files = glob.glob(\"aclImdb/train/neg/*.txt\")\n",
    "train_pos_ls = []\n",
    "for i in train_pos_files:\n",
    "    file = open(i, \"r\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    train_pos_ls.append(str)\n",
    "    \n",
    "train_neg_ls = []\n",
    "for i in train_neg_files:\n",
    "    file = open(i, \"r\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    train_neg_ls.append(str)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['reveiw', 'label']\n",
    "df_train_pos = pd.DataFrame()\n",
    "df_train_pos['review'] = train_pos_ls\n",
    "df_train_pos['label'] = 1\n",
    "df_train_neg = pd.DataFrame()\n",
    "df_train_neg['review'] = train_neg_ls\n",
    "df_train_neg['label'] = -1\n",
    "df_train = pd.concat([df_train_pos , df_train_neg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_files = glob.glob(\"aclImdb/test/pos/*.txt\")\n",
    "test_neg_files = glob.glob(\"aclImdb/test/neg/*.txt\")\n",
    "test_pos_ls = []\n",
    "for i in test_pos_files:\n",
    "    file = open(i, \"r\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    test_pos_ls.append(str)\n",
    "    \n",
    "test_neg_ls = []\n",
    "for i in test_neg_files:\n",
    "    file = open(i, \"r\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    test_neg_ls.append(str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on an actual story, John Boorman shows t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a gem. As a Film Four production - the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I really like this show. It has drama, romance...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the best 3-D experience Disney has at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Of the Korean movies I've seen, only three had...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Based on an actual story, John Boorman shows t...      1\n",
       "1  This is a gem. As a Film Four production - the...      1\n",
       "2  I really like this show. It has drama, romance...      1\n",
       "3  This is the best 3-D experience Disney has at ...      1\n",
       "4  Of the Korean movies I've seen, only three had...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['reveiw', 'label']\n",
    "df_test_pos = pd.DataFrame()\n",
    "df_test_pos['review'] = test_pos_ls\n",
    "df_test_pos['label'] = 1\n",
    "df_test_neg = pd.DataFrame()\n",
    "df_test_neg['review'] = test_neg_ls\n",
    "df_test_neg['label'] = -1\n",
    "df_test = pd.concat([df_test_pos , df_test_neg])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "# nltk stopwords removal performs better than spacy \n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "            \n",
    "def text_prep(text):\n",
    "    no_punct = [char for char in text if char not in string.punctuation]\n",
    "    text = \"\".join(no_punct)\n",
    "    text = [lemma.lemmatize(text, pos='v') for text in text.lower().split() if text not in stops] \n",
    "    text = \" \".join(text)\n",
    "    return (text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie get respect sure lot memorable quote lis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bizarre horror movie fill famous face steal cr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solid unremarkable film matthau einstein wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strange feel sit alone theater occupy parent r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>probably already know 5 additional episodes ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         prep_review  label\n",
       "0  movie get respect sure lot memorable quote lis...      1\n",
       "1  bizarre horror movie fill famous face steal cr...      1\n",
       "2  solid unremarkable film matthau einstein wonde...      1\n",
       "3  strange feel sit alone theater occupy parent r...      1\n",
       "4  probably already know 5 additional episodes ne...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['prep_review'] = df_train['review'].apply(lambda x:text_prep(x))\n",
    "df_train[['prep_review', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base actual story john boorman show struggle a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gem film four production anticipate quality in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really like show drama romance comedy roll one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best 3d experience disney themeparks certainly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>korean movies ive see three really stick first...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         prep_review  label\n",
       "0  base actual story john boorman show struggle a...      1\n",
       "1  gem film four production anticipate quality in...      1\n",
       "2  really like show drama romance comedy roll one...      1\n",
       "3  best 3d experience disney themeparks certainly...      1\n",
       "4  korean movies ive see three really stick first...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess testing data\n",
    "df_test['prep_review'] = df_test['review'].apply(lambda x:text_prep(x))\n",
    "df_test[['prep_review', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing training data \n",
    "tfidf = TfidfVectorizer()\n",
    "# tfidf = TfidfVectorizer(ngram_range = (1,3)) did not improve accuracy\n",
    "x_train = tfidf.fit_transform(df_train['prep_review'])\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing testing data \n",
    "x_test = tfidf.transform(df_test['prep_review'])\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver = 'lbfgs', n_jobs = -1)\n",
    "LR.fit(x_train, y_train)\n",
    "LR_clf = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93544"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88348"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, LR_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'              precision    recall  f1-score   support\\n\\n          -1       0.89      0.88      0.88     12500\\n           1       0.88      0.89      0.88     12500\\n\\n   micro avg       0.88      0.88      0.88     25000\\n   macro avg       0.88      0.88      0.88     25000\\nweighted avg       0.88      0.88      0.88     25000\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, LR_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train, y_train)\n",
    "DT_clf = DT.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.score(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, DT_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVM = LinearSVC()\n",
    "LSVM.fit(x_train, y_train)\n",
    "LSVM_clf = LSVM.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99124"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVM.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, LSVM_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA = AdaBoostClassifier(n_estimators=100)\n",
    "ADA.fit(x_train, y_train)\n",
    "ADA_clf = ADA.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84072"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADA.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83328"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, ADA_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=100, random_state = 42, n_jobs = -1)\n",
    "RFC.fit(x_train, y_train)\n",
    "RFC_clf = RFC.predict(x_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84964"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, RFC_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(x_train, y_train)\n",
    "MNB_clf = MNB.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91724"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83324"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, MNB_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_NN = TfidfVectorizer(max_features = 1000)\n",
    "# x_train_NN = tfidf_NN.fit_transform(df_train['prep_review'])\n",
    "# y_train_NN = df_train['label']\n",
    "# x_test_NN = tfidf_NN.transform(df_test['prep_review'])\n",
    "# y_test_NN = df_test['label']\n",
    "# x_train_NN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Convolution1D, Flatten, Dropout, Dense\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(256, input_shape=(1000,) , activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(160, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(120, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(80, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_NN, y_train_NN, batch_size=128, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x_train_NN, y_train_NN)\n",
    "# print (loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(x_test_NN)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# predictions = rounded\n",
    "# score = accuracy_score(y_test_NN ,predictions)\n",
    "# print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
